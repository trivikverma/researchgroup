{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 80px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/static/media/resources/epa1316/TU_descriptor%20black.png\"> EPA-1316 Introduction to *Urban* Data Science \n",
    "\n",
    "\n",
    "## Assignment 1: Data Collection and Wrangling\n",
    "\n",
    "**TU Delft**<br>\n",
    "**Q1 2020**<br>\n",
    "**Instructor:** Trivik Verma <br>\n",
    "**TAs:** Aarthi Meenakshi Sundaram, Jelle Egbers, Tess Kim, Lotte Lourens, Amir Ebrahimi Fard, Giulia Reggiani, Bramka Jafino <br>\n",
    "**[Computational Urban Science & Policy Lab](https://research.trivikverma.com/)** <br>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "_Note:_ If you have not gone through **labs and homeworks 01-03**, kindly do so before starting this assignment, as those will help you with all the necessary knowledge for this assignment. This assignment will be useful for you when conducting your own statistical analysis as part of the final project for this course or in the future. \n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 01**, using a zipped file **<firstname_lastname_01.zip>** as example,\n",
    "\n",
    "```text\n",
    "trivik_verma_01.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "Please **do not** submit any data or files other than the jupyter notebook. We have the same data as you do.\n",
    "\n",
    "This assignment is designed to support three different learning objectives. After completing this laboratory you will be able to:\n",
    "\n",
    "* Explore variables in a dataset\n",
    "* Manage missing data \n",
    "* Melt, pivot and reshape data to get it in a form useful for statistical analysis \n",
    "\n",
    "This assignment requires you to go through five tasks in cleaning your data. \n",
    "\n",
    "1. Reading and Summarizing the Data.\n",
    "2. Subsetting the Data. This extracts just the part of the data you want to analyse. \n",
    "3. Manage Missing Data. Some data is not available for all objects of interest (rows) or all variables for every object (columns). \n",
    "4. Shape the Data. We need to convert the data into a suitable format for analysis. \n",
    "5. Saving the Results. The results are saved for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Data Frames\n",
    "This assignment puts together what you learned in **Weeks 1-3**. This spreadsheet type format may contain many different data types in the columns. In addition all data frames contain column names, which are strings, and row indices, which are integers. Of course it is very handy to bundle these various kinds of data together to do higher-level tasks, as you will display in this assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download the Data\n",
    "\n",
    "For this assignment we are going to use the World Development Indicators database as a source of data. The World Development Indicators is the primary data source for the World Bank, a financial institution that provides loans to developing nations for investment in national infrastructure. The database is comprised of data from officially recognized sources all over the world. The data consists of time series which in some cases dates back over fifty years. Nations are variously categorized into different groups in order to permit the comparative analysis of nations. \n",
    "\n",
    "You can download the data here as a csv file (It is intentional that I am not explicitly telling you where exactly you will find the csv file on this website):\n",
    "http://data.worldbank.org/data-catalog/world-development-indicators\n",
    "\n",
    "So after you unzip, we’ll work with the file ``WDIData.csv``, which is in a modified csv format. All the other files around it are informative and may be useful for you to do a better analyses. These extra files only provide more information on data sources of indicators used in the main file. Put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. I recommend taking a look at the file in a text editor like _atom_ for any system or notepad++ for windows. These will also make your life easy for everything else on your computer. Make sure you’ve set your working directory in the correct manner – okay?\n",
    "\n",
    "It’s a big file and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment). \n",
    "\n",
    "The data is organized with one country and all the data for one indicator on each line. But there are many countries, and many indicators. Every indicator may have data reaching back from _1960_. These are all shown together on the same line. Because the data is replicated by country, the file is longer than it is wide. We call it “long” data. Thus, each country may be repeated on rows based on the indicator that is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Subsetting the Data\n",
    "\n",
    "From now on we want a much smaller subset of this data. We have all the valid country information using the country code information in ``WDICountry.csv`` or in one of the columns of the main data itself. (Note that it is best practice to search using country codes and not real country names. Countries are known by many names by many different people and languages.) In the future, World Bank may change the datasets with new country names as the data collection efforts of orgs is not relevant to geopolitics. Hence, it is important to work with codes as opposed to names to make our analyses more reproducible across time.\n",
    "\n",
    "The file ``WDISeries.csv`` contains a description of all the indicator variables and their names. We won’t actually use this file in the analysis, but you will find it helpful in designing your own analysis. Your objectives for this assignment is to select **4-7 variables** for further exploratory statistics (more information later in exercises). \n",
    "\n",
    "For example, I can show you what I did, \n",
    "\n",
    "```text\n",
    "My hypothesis\n",
    "I’d like to examine world broadband access. For that reason I chose a broadband account variable. The data is organized by country. I want to control for the wealth, population, and land area of the country. I also have a hypothesis that more urban countries are more likely to have good broadband services. There are economies of scale when providing services to a large city. \n",
    "\n",
    "I hypothesize that larger countries have lesser access, since it is expensive to provide access over larger areas. On the contrary, countries with a lot of urban land area can take advantage of economies of scale resulting in relatively more broadband users concentrated in smaller zones within the country. We also hypothesize that wealthier countries have better broadband access, since there is a larger market to provide the newest services. A final variable which we add is rail lines. I hypothesize that broadband lines can take advantage of existing infrastructure right-of-ways, of which rail is a surrogate measure. Furthermore, the presence of rail lines may indicate other factors including a geography which is conclusive to physical development, and favourable institutional factors which promote high technology development. \n",
    "\n",
    "My choice of variables were, \n",
    "\n",
    "| Variable Name                 | Variable Code     |\n",
    "| ----------------------------- | ----------------- |\n",
    "| Fixed broadband subscriptions | IT.NET.BBND       |\n",
    "| GDP (current US$)             | NY.GDP.MKTP.CD    |\n",
    "| Population, total             | SP.POP.TOTL       |\n",
    "| Land area (sq. km)            | AG.LND.TOTL.K2    |\n",
    "| Urban land area (sq. km)      | AG.LND.TOTL.UR.K2 |\n",
    "| Rail lines (total route-km)   | IS.RRS.TOTL.KM    |\n",
    "\n",
    "```\n",
    "\n",
    "Recall that the data is organized with countries and variables on the rows, and years on the column. Using this table as a guide, I can now extract only those rows which contain these variable names, and throw out the great many other variables that I will not need. You are expected to do the same further down in the exercise. \n",
    "\n",
    "For now let’s set aside the added complexity of time series and dynamics. Our task is to select just one year with a lot of data for most countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Manage Missing Data\n",
    "\n",
    "There is a lot of missing data. If you make the year on which you search too recent, many countries have not been able to report their data. If you make the year too long ago, the practice of administrative data collection had not yet taken hold. Countries did not know that collecting data would be a good thing; furthermore they have yet to back-fill their records. \n",
    "\n",
    "Why is data not available or missing in this dataset?\n",
    "The data availability for urbanisation is especially limited. The urbanisation variable in particular ``AG.LND.TOTL.UR.K2`` is only available per decade. The most recent populated data for this example variable is therefore 2010, in variable ``2010``.\n",
    "It’s quite possible that the World Bank is constructing estimates of urbanisation out of complex data sources such as satellite imagery. Regardless, it appears expensive to compute, and is therefore only offered every decade. \n",
    "\n",
    "We’ve got a number of ways in general of dealing with missing data. These involve\n",
    "\n",
    "1. Dropping off cases (or rows) in the data with any missing variables\n",
    "2. Excluding variables in the data with any missing data \n",
    "3. Selectively choosing indicators with only a limited amount of missing data\n",
    "4. Replacing missing variables with averages, or other representative values\n",
    "5. Creating a separate model to predict missing data\n",
    "\n",
    "In this assignment we are going to use a number of these strategies. We can certainly be dropping off cases (strategy one). I am loathe to drop off whole indicators. But we can, for example, choose a year for the indicator where most of the data is available (strategy three).\n",
    "\n",
    "Building a separate model to impute missing data, is often a good idea. But that requires a first working model before we even consider building a missing data model (and we haven't got there yet in this course); the working model and the missing data model are often constructed together. Note also that there are packages in Python which will construct a model of your data, and then impute missing values for you. You may or may not find these functions and packaging for modelling your data to be fully appropriate. Therefore treat these missing data models very seriously, and not as a black box. Models of missing data are as important, and deserve just as much care and caution as any other statistical model.  \n",
    "\n",
    "In the next section I discuss some specifics about how the data is currently formatted, and how we would like to have it formatted for analysis purposes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reshape the Data\n",
    "\n",
    "As you may have noticed from your outputs above, the data is still not  in a form which is suitable for statistical analysis. Every row is a a combination of a country, a few variables, and a year. We’d like each row instead to be a country, and for there to be many columns according to the variables involved. \n",
    "\n",
    "The data is stored with one country and one variable by year. That’s long data. We want to convert it so each row is a case, and that case is a country. Then each column can store the variables for that country. That’s wide data. Our objectives in this section is to convert from one format of the data to the other. For the purposes of this assignment we’re not going to handle time series data, even though the World Development Indicators data often has many years of time history collected for each of the nations. That's why I asked you to select a particular year only.\n",
    "\n",
    "You might ask why the original data was even stored in this manner. The most efficient means of storing data is to store everything once and then not repeat it. So for instance each element of this data set might be a combination of a country, variable and year. Any additional information, like the full and official name of the country, could be stored in a supplementary table and consulted only at need. \n",
    "\n",
    "That’s the most efficient way. But every user and application is slightly different. As noted above, typically what we need for statistical analysis is a single case on each row, and a set of variables in the columns. Our case is a country, and our variables are things like GDP and population as described above in my example choice of variables. This involves some restructuring of the data which we clearly don’t want to do by hand. Pandas is your best friend here. \n",
    "\n",
    "Reshaping data is a two-step process of melting and pivoting the data. Melting the data involves describing which data are indicators (\"id\") and which are variables for retrieval (“measure”). In this case your data may already be in melted form (long form). Pivoting then involves actually reshaping the data into the needed format. In this step, you have to reshape the data from long to wide format.\n",
    " \n",
    "Pivoting the data involves specifying what data is on the rows and on the columns. Hint: functions melt and pivot offered by ``numpy`` library in python. For our analyses we want “Country.Code” to be on the rows, and to have all 4-7 variables as columns, where the value of each cell is the value taken from the column year that you chose at the subsetting step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise 1: Loading the data``\n",
    "\n",
    "- Load the `WDIData.csv` file into Python\n",
    "- Explore it by looking at first and last 5 rows\n",
    "- Programattically find and print information on the data,\n",
    "    - number of columns in the data\n",
    "    - names of the columns in the data \n",
    "    - number of rows in the data (excluding the header names)\n",
    "    - how many unique regions/countries in the data\n",
    "    - how many unique national indicators in the data\n",
    "    - anything else ...?\n",
    "    \n",
    "- **IMPORTANT** make sure your code can run independent of the machine. i.e. we will store the data in a folder called data and we will run your notebook next to it organised as follows,\n",
    "\n",
    "```text\n",
    "├── trivik_verma_01.ipynb\n",
    "├── data\n",
    "│   ├── WDIData.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise 2: Subsetting the data``\n",
    "\n",
    "- state your hypothesis in a markdown cell as I showed in the example above (there is no single right hypothesis, you are free to make a **reasonable** choice for this task)\n",
    "- find the variables of interest for your hypothesis and mention them in the markdown cell (4-7 variables)\n",
    "- your dataframe would have greatly reduced in size and looks neater, show us what it looks like now using head() or something similar\n",
    "    - show some statistics like number or rows, columns, names of variables and unique countries etc.\n",
    "- you’ll see that your data contains values for many years of data, or perhaps NA (“not applicable”), if the country has failed to report its findings. \n",
    "- For now let’s set aside the added complexity of time series and dynamics. Our task is to select just one year with a lot of data for most countries.\n",
    "    - choose one year/column that you want to work with and drop the rest of the years. \n",
    "\n",
    "You can count the columns manually, but in a large data set like this it is accurate and convenient to let python calculate this for us. Get the index of relevant columns and store them in a variable. \n",
    "\n",
    "- when you do this for your own variables, you also will want to experiment to see which year you want to use. You might also choose to drop off some of your initial variable choices if they are poorly collected. \n",
    "- subset the data by creating a new dataframe only with ``your variables`` `[v1, v2, v3...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise 3: Manage Missing Data``\n",
    "\n",
    "We’ve got a number of ways in general of dealing with missing data. These involve\n",
    "\n",
    "1. Dropping off cases (or rows) in the data with any missing variables\n",
    "2. Excluding variables in the data with any missing data \n",
    "3. Selectively choosing indicators with only a limited amount of missing data\n",
    "4. Replacing missing variables with averages, or other representative values\n",
    "5. Creating a separate model to predict missing data\n",
    "\n",
    "- Count the missing values in each column\n",
    "- Manage the missing values (delete or replace values or leave them as they are) and briefly explain your choice for each column using comments or markdown text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise 4: Reshape the data``\n",
    "\n",
    "- Examine the dimensions of the new pivoted data that you have created. Show it to us using head or print commands.\n",
    "- Then rename all column names to sometyhing better and useful, by replacing codes with their names or shorthand names (ex. AG.LND.TOTL.UR.K2 ---> Urban Land Area).  \n",
    "- Sort the data by putting higher values for one indicator of your choice go first. If there are overlapping values, try to put chronological countries go first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise 5: Saving the results``\n",
    "- Save the cleaned dataframe as 'assignment-01-cleaned.csv' in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
